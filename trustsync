#!/usr/bin/env python3

import urllib.request
import sys
import time
import shlex
import argparse
import os
import re
import ssl

def read_config(config):
    ret = []
    try:
        with open(config) as fp:
            for l in fp:
                ret += shlex.split(l, comments=True)
    except IOError:
        pass
    return ret

def isvalid_fqdn(dn):
    if len(dn) > 255:
        return False
    if re.match('[0-9.]+$', dn):
        return False
    allowed = re.compile('(?!-)[a-z0-9-]{1,63}(?<!-)$', re.IGNORECASE)
    return all(allowed.match(x) for x in dn.split('.'))

def insecure_progressive_download_domains_url(
        url,
        output_file,
        quiet=False,
        chunk_size=8192,
        progress_size=1048576,
        progress_group_size=5):
    ctx = ssl.create_default_context()
    ctx.check_hostname = False
    ctx.verify_mode = ssl.CERT_NONE
    domains = []
    if not quiet:
        print('downloading', url)
    with urllib.request.urlopen(url, context=ctx) as resp:
        with open(output_file, 'wb') as fp:
            downloaded = 0
            progress = 0
            dot_printed = 0
            domain_partial = ''
            while True:
                chunk = resp.read(chunk_size)
                if not chunk:
                    if not quiet:
                        sys.stdout.write('\n')
                        sys.stdout.flush()
                    break
                downloaded += len(chunk)
                domains_chunk = chunk.decode('utf-8').split('\n')
                domains_chunk[0] = domain_partial + domains_chunk[0]
                domain_partial = domains_chunk.pop()
                domains += domains_chunk
                fp.write(chunk)
                if quiet:
                    continue

                progress_buff = downloaded - progress
                if progress_buff >= progress_size:
                    progress_dot = int(progress_buff / progress_size)
                    for i in range(progress_dot):
                        sys.stdout.write('.')
                        sys.stdout.flush()
                        progress += progress_size
                        dot_printed += 1
                        if (dot_printed % progress_group_size) == 0:
                            sys.stdout.write(' ')
                            sys.stdout.flush()
            if domain_partial:
                domains.append(domain_partial)
    return domains

if __name__ == '__main__':
    # default option value
    cache_dir = '/tmp'
    blacklist_domain_file = []
    whitelist_domain_file = []
    cache_urlblock_map = None
    header_zone_template = None
    rr_template = None
    out_zone = None
    post_exec = None

    parser = argparse.ArgumentParser()
    parser.add_argument('--config', default='/etc/trustsync/trustsync.conf')
    parser.add_argument('--cache-dir')
    parser.add_argument('--blacklist-domain-file', action='append')
    parser.add_argument('--whitelist-domain-file', action='append')
    parser.add_argument('--cache-urlblock-map', action='append')
    parser.add_argument('--no-download', action='store_true')
    parser.add_argument('--quiet', action='store_true')
    parser.add_argument('--header-zone-template')
    parser.add_argument('--rr-template')
    parser.add_argument('--out-zone')
    parser.add_argument('--post-exec')
    cmd_args = parser.parse_args()

    cfg = read_config(cmd_args.config)
    cfg_args, ignore = parser.parse_known_args(cfg)

    if cmd_args.cache_dir:
        cache_dir = cmd_args.cache_dir
    elif cfg_args.cache_dir:
        cache_dir = cfg_args.cache_dir

    if cmd_args.blacklist_domain_file:
        blacklist_domain_file = cmd_args.blacklist_domain_file
    elif cfg_args.blacklist_domain_file:
        blacklist_domain_file = cfg_args.blacklist_domain_file

    if cmd_args.whitelist_domain_file:
        whitelist_domain_file = cmd_args.whitelist_domain_file
    elif cfg_args.whitelist_domain_file:
        whitelist_domain_file = cfg_args.whitelist_domain_file

    if cmd_args.cache_urlblock_map:
        cache_urlblock_map = cmd_args.cache_urlblock_map
    elif cfg_args.cache_urlblock_map:
        cache_urlblock_map = cfg_args.cache_urlblock_map

    no_download = cmd_args.no_download or cfg_args.no_download
    quiet = cmd_args.quiet or cfg_args.quiet

    if cmd_args.header_zone_template:
        header_zone_template = cmd_args.header_zone_template
    elif cfg_args.header_zone_template:
        header_zone_template = cfg_args.header_zone_template

    if cmd_args.rr_template:
        rr_template = cmd_args.rr_template
    elif cfg_args.rr_template:
        rr_template = cfg_args.rr_template

    if cmd_args.out_zone:
        out_zone = cmd_args.out_zone
    elif cfg_args.out_zone:
        out_zone = cfg_args.out_zone

    if cmd_args.post_exec:
        post_exec = cmd_args.post_exec
    elif cfg_args.post_exec:
        post_exec = cfg_args.post_exec

    if (not blacklist_domain_file and
        not whitelist_domain_file and
        not cache_urlblock_map):
        if not quiet:
            print("no such input")
        quit()

    if not out_zone:
        if not quiet:
            print("--out-zone must be specified")
        quit()

    if not header_zone_template:
        if not quiet:
            print("--header-zone-template must be specified")
        quit()

    if not rr_template:
        if not quiet:
            print("--rr-template must be specified")
        quit()

    domains = []
    cache_uptodate = []
    if cache_urlblock_map:
        for cache_url in cache_urlblock_map:
            cache, url = cache_url.split(':', 1)
            cache = cache_dir + '/' + cache
            if not no_download:
                domains.extend(
                    insecure_progressive_download_domains_url(
                        url,
                        cache))
            cache_uptodate.append(cache)

    whitelist_domain = {}
    for domain_file in whitelist_domain_file:
        with open(domain_file) as fp:
            for l in fp:
                if l.startswith('#'):
                    continue
                domain = l.strip()
                whitelist_domain[domain] = True

    with open(header_zone_template) as fp:
        header_zone = fp.read()

    with open(rr_template) as fp:
        rr = fp.read()

    serial = time.strftime('%Y%m%d01')

    with open(out_zone, 'w') as fp:
        fp.write(header_zone.replace('{serial}', serial))

        block_domain = {}
        for domain in domains:
            # validate domain and write to out zone
            domain = domain.strip()
            if domain.startswith('*.'):
                domain = domain[2:]
            if domain.endswith('.'):
                domain = domain[:-1]
            if not isvalid_fqdn(domain):
                if not quiet:
                    print('invalid domain', domain)
                continue
            if domain in whitelist_domain:
                continue
            if domain in block_domain:
                continue
            block_domain[domain] = True
            fp.write(rr.replace('{name}', domain))

        for cache in cache_uptodate:
            with open(cache) as fpc:
                for l in fpc:
                    domain = l.strip()
                    if domain.endswith('.'):
                        domain = domain[:-1]
                    if not isvalid_fqdn(domain):
                        if quiet:
                            continue
                        print('invalid domain', domain)
                        continue
                    if domain in whitelist_domain:
                        continue
                    if domain in block_domain:
                        continue
                    block_domain[domain] = True
                    fp.write(rr.replace('{name}', domain))

        for domain_file in blacklist_domain_file:
            with open(domain_file) as fpd:
                for l in fpd:
                    domain = l.strip()
                    if domain.startswith('#'):
                        continue
                    if domain in whitelist_domain:
                        continue
                    if domain in block_domain:
                        continue
                    block_domain[domain] = True
                    fp.write(rr.replace('{name}', domain))

    if post_exec:
        os.system(post_exec)
